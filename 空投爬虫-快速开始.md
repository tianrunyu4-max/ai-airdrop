# 🚀 空投爬虫系统 - 快速开始

## ✅ 已完成功能

### 1. **数据库表结构** ✅
- ✅ `airdrops` - 空投信息表
- ✅ `airdrop_pushes` - 推送历史表
- ✅ `airdrop_sources` - 数据源配置表
- ✅ AI评分函数
- ✅ 自动去重机制

### 2. **爬虫服务** ✅
- ✅ Layer3.xyz 爬虫
- ✅ Galxe.com 爬虫
- ✅ DeFiLlama 爬虫
- ✅ Twitter 爬虫（可选）
- ✅ 中文资讯爬虫
- ✅ 定时任务（每6小时）
- ✅ 数据清洗和去重
- ✅ AI智能评分

### 3. **前端机器人** ✅
- ✅ 从数据库读取空投
- ✅ 90% Web3 + 10% CEX 分配
- ✅ 备用硬编码数据（数据库为空时）
- ✅ 自动推送（每天10:00 + 20:00）
- ✅ 消息格式化
- ✅ 推送历史记录

---

## ⚡ 3步部署

### 第1步：创建数据库表

在 Supabase SQL Editor 中执行：

```sql
-- 复制 supabase/migrations/创建空投爬虫系统.sql 的内容
-- 粘贴到SQL Editor并运行
```

### 第2步：安装爬虫依赖

```bash
npm install axios cheerio node-cron
```

### 第3步：启动爬虫（3种方式任选其一）

#### 方式A：本地测试（立即执行一次）
```bash
npm run crawler
```

#### 方式B：后台运行（使用PM2）
```bash
npm install -g pm2
pm2 start scripts/airdrop-crawler.mjs --name airdrop-crawler
pm2 logs airdrop-crawler
```

#### 方式C：手动模式（不启动爬虫）
- 跳过爬虫部署
- 前端会使用备用的硬编码数据
- 适合快速测试

---

## 📊 数据流程

```
1. 爬虫每6小时抓取数据（0/6/12/18点）
   ↓
2. 数据存入 airdrops 表（自动去重、AI评分）
   ↓
3. 前端机器人每天推送2次（10:00 + 20:00）
   ↓
4. 从数据库随机选5-10个优质空投（评分≥7.0）
   ↓
5. 推送到 AI科技 群聊
```

---

## 🎯 推送策略

### 时间
- **早上 10:00**：推送5-10个空投
- **晚上 20:00**：推送5-10个空投

### 规则
- ✅ 只推送 AI评分 ≥ 7.0 的优质空投
- ✅ 90% Web3 高价值空投（500-10000 USDT）
- ✅ 10% 交易所空投（50-200 USDT）
- ✅ 12小时内推送过的不重复推送
- ✅ 按评分从高到低排序

---

## 📝 数据源

| 平台 | 类型 | 优先级 | 说明 |
|------|------|--------|------|
| Layer3.xyz | API | ⭐⭐⭐⭐⭐ | 任务型空投，奖励明确 |
| Galxe.com | API | ⭐⭐⭐⭐⭐ | 最大Web3任务平台 |
| DeFiLlama | API | ⭐⭐⭐⭐ | DeFi项目，潜在空投 |
| Foresight News | 爬虫 | ⭐⭐⭐⭐ | 中文资讯，整理好的信息 |
| Twitter | API | ⭐⭐⭐ | 实时性强，但噪音多 |

---

## 🔧 管理命令

### 查看爬虫状态
```bash
pm2 status
pm2 logs airdrop-crawler --lines 100
```

### 手动触发爬虫
```bash
npm run crawler
```

### 查看数据库数据
```sql
-- 查看空投总数
SELECT COUNT(*) FROM airdrops;

-- 查看优质空投（评分≥7.0）
SELECT title, platform, ai_score, reward_max
FROM airdrops
WHERE status = 'active' AND ai_score >= 7.0
ORDER BY ai_score DESC
LIMIT 20;

-- 查看推送历史
SELECT 
  a.title,
  a.push_count,
  a.last_pushed_at
FROM airdrops a
WHERE push_count > 0
ORDER BY push_count DESC
LIMIT 10;
```

---

## 💡 使用建议

### **新手（推荐）**
- 跳过爬虫部署
- 使用内置的9个热门Web3项目
- 后期可手动添加数据到数据库

### **进阶**
- 部署爬虫到本地服务器（PM2）
- 每6小时自动抓取最新空投
- 定期查看日志和优化评分算法

### **专家**
- 自定义爬虫数据源
- 对接更多API（Twitter, TaskOn等）
- 开发管理后台，可视化管理空投

---

## 🐛 常见问题

### Q1：爬虫报错怎么办？
**A**：不影响使用，前端会自动使用备用数据（硬编码的9个项目）

### Q2：如何添加更多数据源？
**A**：编辑 `scripts/airdrop-crawler.mjs`，参考现有爬虫代码添加新的数据源

### Q3：如何调整推送时间？
**A**：修改 `src/views/chat/ChatView.vue` 中的 `startAirdropBot()` 函数

### Q4：如何手动添加空投到数据库？
**A**：在 Supabase SQL Editor 中执行：
```sql
INSERT INTO airdrops (title, platform, type, ai_score, reward_min, reward_max, difficulty, status)
VALUES 
('LayerZero空投', 'Layer3', 'web3', 9.8, 1000, 10000, 'medium', 'active'),
('币安Launchpool', 'Binance', 'cex', 8.2, 50, 200, 'easy', 'active');
```

### Q5：如何清理过期空投？
**A**：
```sql
DELETE FROM airdrops WHERE status = 'expired' AND created_at < NOW() - INTERVAL '30 days';
```

---

## 📈 下一步优化

- [ ] 添加更多数据源（TaskOn, Zealy, Quest3）
- [ ] 集成GPT-4进行智能筛选和内容优化
- [ ] 开发管理后台（可视化管理空投）
- [ ] 添加用户反馈（点赞/收藏/举报）
- [ ] 实现Telegram Bot推送
- [ ] 添加空投完成追踪

---

## 📚 详细文档

- 📖 [完整使用指南](./空投爬虫系统使用指南.md)
- 📂 [数据库SQL](./supabase/migrations/创建空投爬虫系统.sql)
- 🕷️ [爬虫代码](./scripts/airdrop-crawler.mjs)
- 🎨 [前端服务](./src/services/AirdropService.ts)

---

## 🎉 总结

### **当前状态**：✅ 完全可用

- ✅ **数据库**：表结构已创建，支持多源数据
- ✅ **爬虫**：5个数据源，AI评分，自动去重
- ✅ **前端**：智能推送，90%Web3+10%CEX
- ✅ **备用**：硬编码9个热门项目（数据库为空时）

### **部署选项**

1. **最简单**：不部署爬虫，使用内置数据 ⭐⭐⭐⭐⭐
2. **推荐**：部署爬虫到本地，自动更新 ⭐⭐⭐⭐
3. **高级**：自定义数据源，专业运营 ⭐⭐⭐

---

**🚀 现在就可以开始使用了！**

如有问题，请参考 [详细文档](./空投爬虫系统使用指南.md) 或联系管理员。

